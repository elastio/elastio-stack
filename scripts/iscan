#!/usr/bin/env bash
set -eu -o pipefail
# set -x
export PS4='+ [${BASH_SOURCE[0]##*/}:${LINENO}${FUNCNAME[0]:+:${FUNCNAME[0]}}] '

# The registry where the `iscan` Docker image can be found.
#
# To use local image, set this to an empty string when launching the script,
# e.g.
#     REGISTRY= ./iscan $volume
#
# To pull the image from private Amazon ECR:
#     REGISTRY="${aws_account_id}.dkr.ecr.${region}.amazonaws.com/" ./iscan $volume
#
DEFAULT_REGISTRY='public.ecr.aws/elastio-dev/'
REGISTRY=${REGISTRY-$DEFAULT_REGISTRY}

DEFAULT_S3_BUCKET='elastio-rw-reports-test-bucket'
S3_BUCKET=${S3_BUCKET-$DEFAULT_S3_BUCKET}

prog="${0##*/}"

usage() {
    cat <<EOF
Scan a filesystem volume for the signs of detonated ransomware and dormant malware.
Upload the compressed archive with scan results to S3.

USAGE:
    $prog [--for (malware|ransomware|both)] [-N | --name=<stem>] [-y | --upload] [--] <volume>
    $prog upload [--] <file>

OPTIONS:
    -h, --help         Show this help and exit
        --for <what>   Type of scan to perform ("malware"|"ransomware"|"both") (default "both")
    -N, --name <stem>
        The "stem" of output files, i.e., the filename stripped of directory and extension.
        Default is "iscan-\$HOSTNAME-\$(basename \$volume)-\$(date --utc +%y%m%d-%H%M%S)",
        which gets evaluated to something like "iscan-ip-172-31-44-103-nvme1n1p1-211031-125142"
    -y, --upload       Answer "yes" to the upload confirmation dialog.
                       To skip S3 upload, set S3_BUCKET environment variable to
                       an empty string.

SUBCOMMANDS:
    upload      Send the file with scan results to the S3 bucket.  See S3_BUCKET
                in ENVIRONMENT VARIABLES section below.

POSITIONAL ARGUMENTS:
    <file>      Path to a locally saved file with scan results
    <volume>    Directory, block device, or ID of the recovery point to scan

ENVIRONMENT VARIABLES:
    REGISTRY    The registry where 'iscan' Docker image can be found (default: '$DEFAULT_REGISTRY').
                To use local image, set REGISTRY to an empty string.
    S3_BUCKET   S3 bucket to upload scan results to (default: '$DEFAULT_S3_BUCKET').
                Setting S3_BUCKET to an empty string disables S3 upload.

RETURN VALUE:
    $prog exits with code 0 if the processing succeeded and no hazards were found.
    If malware or ransomware hazards were detected, $prog exits with code 201-203:

    201   Signs of exploded ransomware were found.
    202   Malware was found.
    203   Both malware and signs of exploded ransomware were found.

    Any other non-zero exit code means that processing failed.
EOF
}

opt_name=
opt_for='both'
opt_upload=false
opt_arg=

DOCKER=

optparse_scan() {
    local temp
    temp=$(getopt -o h,N:,y --long help,for:,name:,upload --name "$prog" -- "$@")
    eval set -- "$temp"

    while true; do
        case "$1" in
            -h|--help)
                usage
                exit
                ;;
            --for)
                case "$2" in
                    malware|ransomware|both)
                        opt_for="$2"
                        ;;
                    *)
                        die 'Invalid --for argument'
                        ;;
                esac
                shift
                ;;
            -N|--name)
                opt_name="$2"
                shift
                ;;
            -y|--upload)
                opt_upload=true
                ;;
            --)
                shift
                break
                ;;
            *)
                die "[$prog:$LINENO] BUG"  # unreachable
                ;;
        esac
        shift
    done

    (( $# == 1 )) ||
        die "Wrong number of arguments.  Type '$prog --help' for usage."
    opt_arg="$1"

    if $opt_upload && [[ -z $S3_BUCKET ]]; then
        die "'--upload' conflicts with S3_BUCKET set to an empty string"
    fi
}

optparse_upload() {
    local temp
    temp=$(getopt -o h --long help --name "$prog" -- "$@")
    eval set -- "$temp"

    while true; do
        case "$1" in
            -h|--help)
                usage
                exit
                ;;
            --)
                shift
                break
                ;;
            *)
                die "[$prog:$LINENO] BUG"  # unreachable
                ;;
        esac
        shift
    done

    [[ -n $S3_BUCKET ]] || die 'Cannot upload with S3_BUCKET set to an empty string'

    (( $# == 1 )) || die 'Which file to upload?'
    opt_arg="$1"
}

die() {
    echo "$@" >&2
    exit 1
}

# https://github.com/git/git/blob/9d530dc0024503ab4218fe6c4395b8a0aa245478/color.h#L25
GIT_COLOR_RESET='\033[m'
GIT_COLOR_BOLD_RED='\033[1;31m'
GIT_COLOR_BOLD_GREEN='\033[1;32m'
GIT_COLOR_BOLD_YELLOW='\033[1;33m'
GIT_COLOR_BOLD_BLUE='\033[1;34m'

# https://github.com/git/git/blob/9d530dc0024503ab4218fe6c4395b8a0aa245478/color.c#L420
color_print() {
    (( $# == 2 || $# == 3)) || die "[$prog:$LINENO] BUG: Invalid usage"
    local color="$1"
    local text="$2"
    local trail="${3-\n}"

    printf "${color}%s${GIT_COLOR_RESET}${trail}" "$text"
}

print_info() {
    color_print "$GIT_COLOR_BOLD_GREEN" "$@" >&2
}

print_warning() {
    color_print "$GIT_COLOR_BOLD_YELLOW" "$@" >&2
}

print_error() {
    color_print "$GIT_COLOR_BOLD_RED" "$@" >&2
}

check_docker() {
    # Make sure Docker is installed and the daemon is running.
    if [[ -n $(type -p docker) ]]; then
        DOCKER='docker'
    else
        DOCKER='sudo docker'
    fi
    $DOCKER --version >& /dev/null || {
        print_error 'Docker is not installed'
        print_warning 'See https://docs.docker.com/engine/install/'
        exit 1
    }
    $DOCKER ps >/dev/null
}

# Login to Amazon ECR (the container image registry).
#
# Whenever possible docker pulls should be coming from the "authenticated" pool
# and not the "anonymous" pool, since the free bandwidth cap is much higher for
# the authenticated.
docker_login() {
    local registry=$1
    [[ -n $registry ]] || die "[$prog:$LINENO] BUG: ${FUNCNAME[0]}: Invalid usage"

    if [[ $registry =~ ^public\.ecr\.aws ]]; then
        # Public ECR is always in 'us-east-1'.
        aws --region us-east-1 ecr-public get-login-password 2>/dev/null
    else
        # It looks like we are dealing with a private Amazon ECR;
        # see https://docs.aws.amazon.com/AmazonECR/latest/userguide/Registries.html#registry_concepts
        aws ecr get-login-password 2>/dev/null
    fi |
        $DOCKER login --username AWS --password-stdin $registry &>/dev/null ||
        print_warning 'AWS authentication is not available. Proceeding anonymously.'
}

iscan_opts() {
    (( $# == 1 )) || die "[$prog:$LINENO] BUG: Invalid usage"
    local volume="$1"

    case $opt_for in
        both|malware|ransomware)
            echo "scan $volume $opt_for"
            ;;
        *)
            die "[$prog:$LINENO] BUG: Impossible happened"
    esac
}

# Scan the volume.
iscan() {
    (( $# == 3 )) || die "[$prog:$LINENO] BUG: Invalid usage"
    local image=$1
    local volume="$2"
    local out_file="$3"

    # The file where the exit code of `docker run` will be stored.
    #
    # Environment variables set in a pipeline
    # (e.g., `{ docker run ... || ret=$?; } | gzip`) are not visible by the
    # parent shell.
    #
    # bash(1):
    #
    # > Each command in a pipeline is executed as a separate process
    # > (i.e., in a subshell).
    local ret_file="${TMPDIR:-/tmp}/_$prog.ret"
    trap "rm -f $ret_file" 0

    # REVIEW: We cannot pass `--tty` flag to `docker run`.  If we did, `docker run`
    # would merge stdout and stderr, and the output archive would be garbage.
    # And without `--tty` we can't see the spinners --- `indicatif` hides them.
    #
    # [https://docs.rs/indicatif/latest/indicatif/#progress-bars-and-spinners]
    # | General progress bar behaviors:
    # |
    # | * if a non terminal is detected the progress bar will be completely hidden.
    # |   This makes piping programs to logfiles make sense out of the box.
    echo 0 > $ret_file
    print_info 'Scanning... ' ''
    if [[ -d "$volume" ]]; then
        $DOCKER run --rm \
            --mount readonly,type=bind,source="$(readlink -f "$volume")",destination=/vol \
            --env STEM="$name" \
            $image \
            $(iscan_opts /vol) || echo $? > $ret_file
    elif [[ -b "$volume" ]]; then
        $DOCKER run --rm --privileged \
            --env STEM="$name" \
            $image \
            $(iscan_opts "$volume") || echo $? > $ret_file
    elif [[ "$volume" =~ ^r-[a-z0-9]{24}$ ]]; then
        # - AWS credentials are needed to run `elastio mount` from within docker.
        # - /lib/modules are required to `insmod nbd`.
        # - And /dev gives the container access to NBD device.
        $DOCKER run --rm --privileged \
            -v ~/.aws:/root/.aws:ro \
            -v /lib/modules:/lib/modules:ro \
            -v /dev:/dev \
            --env STEM="$name" \
            $image \
            $(iscan_opts "$volume") || echo $? > $ret_file
    else
        die "$volume is neither a directory, nor a block device, nor a recovery point ID"
    fi |
        gzip > $out_file
    print_info 'done'

    return $(cat $ret_file)
}

cmd_scan() {
    (( $# == 1 )) || die "[$prog:$LINENO] BUG: Invalid usage"
    local volume="$1"

    local name="$opt_name"
    if [[ -z $name ]]; then
        # A tar archive with colon in its name is not easy to unpack --
        # GNU tar needs a special flag for that.
        #
        #   $ tar -tf 'iscan-ip-172-31-3-187-D:\-211119-203917.tar'
        #   tar: Cannot connect to iscan-ip-172-31-3-187-D: resolve failed
        #
        #   $ tar --force-local -tf 'iscan-ip-172-31-3-187-D:\-211119-203917.tar.gz'
        #   iscan-ip-172-31-3-187-D:\\-211119-203917_malware.json
        #   iscan-ip-172-31-3-187-D:\\-211119-203917_ransomware.html
        #   iscan-ip-172-31-3-187-D:\\-211119-203917_ransomware.json
        #
        # The purpose of the `tr`-ickery below is to remove colons, backslashes,
        # and other nonsence symbols from Windows paths.
        name=$(basename "$volume" | tr -dc '[:alnum:]-')
        name="iscan-$HOSTNAME-$name-$(date --utc +%y%m%d-%H%M%S)"
    fi

    REGISTRY=${REGISTRY%/}            # strip trailing slash, if any
    REGISTRY=${REGISTRY:+$REGISTRY/}  # if non-empty, add a trailing slash

    local image=${REGISTRY}iscan:latest
    check_docker
    if [[ -n $REGISTRY ]]; then
        docker_login $REGISTRY
        # Ensure we use the most recent image.
        $DOCKER pull $image
    fi

    # The output file.  It will be removed if `docker run` fails.
    local out="${TMPDIR:-/tmp}/$name.ndjson.gz"
    # XXX TODO: If $out exists, ask the user if it's OK to overwrite it.
    trap "rm -f $out" 0

    local ret=0
    iscan $image "$volume" "$out" || ret=$?

    if (( ret == 0 || (201 <= ret && ret <= 203) )); then
        # The output file has been generated successfully, and we want to keep it.
        # Unset the trap that would remove the file.
        trap - 0
        print_info "Results saved to $out"
    else
        print_error "$prog failed, exit code $ret"
        return $ret
    fi

    if [[ -z $S3_BUCKET ]]; then
        # S3_BUCKET is set to an empty string ==> don't upload anything.
        return $ret
    fi

    while ! $opt_upload; do
        color_print "$GIT_COLOR_BOLD_BLUE" \
            "Upload this file to s3://$S3_BUCKET/ [y,n]? " ''
        read -r
        case "${REPLY,,}" in
            y|yes)
                opt_upload=true
                ;;
            n|no)
                return $ret
                ;;
        esac
    done

    if $opt_upload; then
        cmd_upload $out
    fi
    return $ret
}

cmd_upload() {
    (( $# == 1 )) || die "[$prog:$LINENO] BUG: Invalid usage"
    local file="$1"

    [[ -n $S3_BUCKET ]] || die "[$prog:$LINENO] BUG"

    # Check if AWS CLI is installed.
    if [[ -z $(type -p aws) ]] || ! aws --version >/dev/null; then
        print_error 'Cannot upload the file'
        print_warning 'Install AWS CLI tool. See'
        print_warning 'https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html'
        exit 1
    fi

    # XXX TODO: Check if this is indeed a file with iscan results.

    if [[ $S3_BUCKET == $DEFAULT_S3_BUCKET ]]; then
        # $DEFAULT_S3_BUCKET is world-writable.  Let the bucket owner (Elastio)
        # have full control over the object.
        # See https://docs.aws.amazon.com/AmazonS3/latest/userguide/acl-overview.html#canned-acl
        local opt_acl='--acl bucket-owner-full-control'
    fi
    # XXX TODO: Use `--metadata` option of `aws s3 cp` command.
    aws s3 cp ${opt_acl:-} --quiet "$file" s3://$S3_BUCKET/
    print_info "Results uploaded to s3://$S3_BUCKET/${file##*/}"
}

main() {
    local cmd='scan'
    if [[ "${1:-}" == 'upload' ]]; then
        cmd='upload'
        shift
    fi
    optparse_$cmd "$@"
    cmd_$cmd "$opt_arg"
}

main "$@"
